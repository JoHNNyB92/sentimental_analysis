{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob import classifiers\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk import precision,recall\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv that contain only the test tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20342\n"
     ]
    }
   ],
   "source": [
    "cols = ['id','sentiment','tweet']\n",
    "te_files=['twitter-2016test-A.tsv']\n",
    "list_=[]\n",
    "for file_ in te_files:\n",
    "    df = pd.read_csv(file_,names=cols, header=None,sep='\\t')\n",
    "    list_.append(df)\n",
    "df_test = pd.concat(list_)\n",
    "print len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tweets that their text has any useless (for sentiment analysis purposes) mentions to other users,html links,hashtag symbol from hashtags and RT (retweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "def clean_tweet(tweet):\n",
    "    words_filtered = [e.lower() for e in tweet.split() if len(e) >= 3]\n",
    "    words_cleaned = [word.translate(None, string.punctuation) for word in words_filtered\n",
    "    if 'http' not in word\n",
    "    and not word.startswith('@')\n",
    "    and not word.startswith('#')\n",
    "    and word != 'RT'\n",
    "    and word not in stopwords_set]\n",
    "    words_without_stopwords = [word for word in words_cleaned if not word in stopwords_set]\n",
    "    return words_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the textblob already implemented function that counts the sentiment of a sentence and produce a float value between -1 and 1. Values greater than 0 are counted as positive and values lower than 0 count as negative.Values equal to 0 are neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target=[]\n",
    "result=[]\n",
    "for i,v in df_test.iterrows():\n",
    "    if v['tweet']!='Not Available':\n",
    "        text=' '.join(clean_tweet(v['tweet']))\n",
    "        blob = TextBlob(text)\n",
    "        target.append(v['sentiment'])\n",
    "        if blob.sentiment[0]<0:\n",
    "            result.append('negative')\n",
    "        elif blob.sentiment[0]>0:\n",
    "            result.append('positive')\n",
    "        else:\n",
    "            result.append('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.49      0.62      0.55      5439\n",
      "   negative       0.30      0.40      0.34      2271\n",
      "    neutral       0.61      0.43      0.50      7727\n",
      "\n",
      "avg / total       0.52      0.49      0.50     15437\n",
      "\n",
      "Accuracy  0.493878344238\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(metrics.classification_report(target, result,['positive','negative','neutral']))\n",
    "metrics.confusion_matrix(target,result)\n",
    "print 'Accuracy ',accuracy_score(result,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h4>As we can see,this already implemented version for sentiment analysis produces generally worst results than the algorithm we selected.\n",
    "This is normal as the algorithm depends vastly on the input data that will be presented to produce the vocabulary whereas this implementation has a static vocabulary</h4>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
