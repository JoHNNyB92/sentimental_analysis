{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk import precision,recall\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the two files and put them in a pandas dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train tweets read  16045\n",
      "Total test tweets read  20342\n",
      "Total dev train tweets read  2000\n",
      "Total dev test tweets read  489\n"
     ]
    }
   ],
   "source": [
    "cols = ['id','sentiment','tweet']\n",
    "tr_files=['twitter-2013train-A.tsv','twitter-2015train-A.tsv','twitter-2016train-A.tsv']\n",
    "dev_files_te='twitter-2016dev-A.tsv'\n",
    "dev_files_tr='twitter-2016devtest-A.tsv'\n",
    "te_files='twitter-2016test-A.tsv'\n",
    "list_=[]\n",
    "for file_ in tr_files:\n",
    "    df = pd.read_csv(file_,names=cols, header=None,sep='\\t')\n",
    "    list_.append(df)\n",
    "df_train = pd.concat(list_)\n",
    "\n",
    "df = pd.read_csv(te_files,names=cols, header=None,sep='\\t')\n",
    "df_test=df\n",
    "    \n",
    "df = pd.read_csv(dev_files_tr,names=cols, header=None,sep='\\t')\n",
    "df_dev_tr = df\n",
    "\n",
    "df = pd.read_csv(dev_files_te,names=cols, header=None,sep='\\t')\n",
    "df_dev_te = df\n",
    "\n",
    "print 'Total train tweets read ',len(df_train)\n",
    "print 'Total test tweets read ',len(df_test)\n",
    "print 'Total dev train tweets read ',len(df_dev_tr)\n",
    "print 'Total dev test tweets read ',len(df_dev_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the datasets that their tweets are available.Remove the ones that their tweet text says 'Not available'. I decided also to remove the neutral category and to keep only the tweets that express a feeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of train data:                    id sentiment  \\\n",
      "0  264183816548130816  positive   \n",
      "3  264249301910310912  negative   \n",
      "6  264105751826538497  positive   \n",
      "7  264094586689953794  negative   \n",
      "9  254941790757601280  negative   \n",
      "\n",
      "                                               tweet  \n",
      "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
      "3  Iranian general says Israel's Iron Dome can't ...  \n",
      "6  with J Davlar 11th. Main rivals are team Polan...  \n",
      "7  Talking about ACT's &amp;&amp; SAT's, deciding...  \n",
      "9  They may have a SuperBowl in Dallas, but Dalla...  \n",
      "Sample of test data:                    id sentiment  \\\n",
      "0  619950566786113536   neutral   \n",
      "1  619969366986235905   neutral   \n",
      "3  619974445185302528   neutral   \n",
      "4  619987808317407232  positive   \n",
      "5  619994586182619136  positive   \n",
      "\n",
      "                                               tweet  \n",
      "0  Picturehouse's, Pink Floyd's, 'Roger Waters: T...  \n",
      "1  Order Go Set a Watchman in store or through ou...  \n",
      "3  If you could ask an onstage interview question...  \n",
      "4  A portion of book sales from our Harper Lee/Go...  \n",
      "5  Excited to read \"Go Set a Watchman\" on Tuesday...  \n"
     ]
    }
   ],
   "source": [
    "df_train=df_train[df_train.tweet!='Not Available']\n",
    "df_test=df_test[df_test.tweet!='Not Available']\n",
    "df_dev_te=df_dev_te[df_dev_te.tweet!='Not Available']\n",
    "df_dev_tr =df_dev_tr[df_dev_tr.tweet!='Not Available']\n",
    "print 'Sample of train data:',df_train.head()\n",
    "print 'Sample of test data:',df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of sentimens (positive,negative neutral) that exist in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiments in train: neutral     5143\n",
      "positive    5117\n",
      "negative    1658\n",
      "Name: sentiment, dtype: int64\n",
      "Sentiments in test: neutral     7727\n",
      "positive    5439\n",
      "negative    2271\n",
      "Name: sentiment, dtype: int64\n",
      "Sentiments in dev train test: positive    777\n",
      "neutral     539\n",
      "negative    246\n",
      "Name: sentiment, dtype: int64\n",
      "Sentiments in dev test: neutral     199\n",
      "positive    116\n",
      "negative     41\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print 'Sentiments in train:',df_train.sentiment.value_counts()\n",
    "print 'Sentiments in test:',df_test.sentiment.value_counts()\n",
    "print 'Sentiments in dev train test:',df_dev_tr.sentiment.value_counts()\n",
    "print 'Sentiments in dev test:',df_dev_te.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the neccessary columns and drop id column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_tr=df_train[['tweet','sentiment']]\n",
    "d_te=df_test[['tweet','sentiment']]\n",
    "dev_tr=df_dev_tr[['tweet','sentiment']]\n",
    "dev_te=df_dev_te[['tweet','sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count and put the two different type of centiments(positive,negative) that exist in the test dataset in a different list in order to perform evaluation later on and compare the classifier result with the expected one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pos = d_te[d_te['sentiment'] == 'positive']\n",
    "t_pos = t_pos['tweet']\n",
    "t_neg = d_te[ d_te['sentiment'] == 'negative']\n",
    "t_neg = t_neg['tweet']\n",
    "t_neu = d_te[ d_te['sentiment'] == 'neutral']\n",
    "t_neu = t_neu['tweet']\n",
    "\n",
    "d_pos = dev_te[dev_te['sentiment'] == 'positive']\n",
    "d_pos = d_pos['tweet']\n",
    "d_neg = dev_te[ dev_te['sentiment'] == 'negative']\n",
    "d_neg = d_neg['tweet']\n",
    "d_neu = dev_te[ dev_te['sentiment'] == 'neutral']\n",
    "d_neu = d_neu['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tweets that their text has any useless (for sentiment analysis purposes) mentions to other users,html links,hashtag symbol from hashtags and RT (retweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_tr=[]\n",
    "dev_tweets=[]\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "for index, row in d_tr.iterrows():\n",
    "    words_filtered = [e.lower() for e in row.tweet.split() if len(e) >= 3]\n",
    "    words_cleaned = [word.translate(None, string.punctuation) for word in words_filtered\n",
    "        if 'http' not in word\n",
    "        and not word.startswith('@')\n",
    "        and not word.startswith('#')\n",
    "        and word != 'RT'\n",
    "        and word not in stopwords_set]\n",
    "    words_without_stopwords = [word for word in words_cleaned if not word in stopwords_set]\n",
    "    tweets_tr.append((words_cleaned,row.sentiment))\n",
    "\n",
    "for index, row in dev_tr.iterrows():\n",
    "    words_filtered = [e.lower() for e in row.tweet.split() if len(e) >= 3]\n",
    "    words_cleaned = [word.translate(None, string.punctuation) for word in words_filtered\n",
    "        if 'http' not in word\n",
    "        and not word.startswith('@')\n",
    "        and not word.startswith('#')\n",
    "        and word != 'RT'\n",
    "        and word not in stopwords_set]\n",
    "    words_without_stopwords = [word for word in words_cleaned if not word in stopwords_set]\n",
    "    dev_tweets.append((words_cleaned,row.sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_word_in_tweets:get the tweet text and put all the words in a list.\n",
    "\n",
    "get_word_features:get the previous word list in order to keep only the words tha exist in ntlk.\n",
    "\n",
    "extract_features:To create a classifier, we need to decide what features are relevant. To do that, we first need a feature extractor. The one we are going to use returns a dictionary indicating what words are contained in the input passed. Here, the input is the tweet. We use the word features list defined above along with the input to create the dictionary.The return list is of the form (contains(word),False or True) if the word is contained or not ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_in_tweets(tweets):\n",
    "    all = []\n",
    "    for (words, sentiment) in tweets:\n",
    "        words=[x for x in words if x!='' and x!=' ']\n",
    "        all.extend(words)\n",
    "    return all\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    features = wordlist.keys()\n",
    "    return features\n",
    "\n",
    "def extract_features_tr(document):\n",
    "    document_words = set([w.lower().translate(None, string.punctuation) for w in document])\n",
    "    features = {}\n",
    "    for word in w_features_tr:\n",
    "        features['contains(%s)' % (word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "def extract_features_dev(document):\n",
    "    document_words = set([w.lower().translate(None, string.punctuation) for w in document])\n",
    "    features = {}\n",
    "    for word in w_features_dev:\n",
    "        features['contains(%s)' % (word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "w_features_tr = get_word_features(get_words_in_tweets(tweets_tr))\n",
    "w_features_dev= get_word_features(get_words_in_tweets(dev_tweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-1d126f522094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mscuser/anaconda2/lib/python2.7/site-packages/nltk/classify/naivebayes.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Count up how many times each feature value occurred, given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# the label and featurename.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mlabel_freqdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mscuser/anaconda2/lib/python2.7/site-packages/nltk/collections.pyc\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lists\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mscuser/anaconda2/lib/python2.7/site-packages/nltk/classify/util.pyc\u001b[0m in \u001b[0;36mlazy_func\u001b[0;34m(labeled_token)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabeled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlazy_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mLazyMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-158-faac31a188a5>\u001b[0m in \u001b[0;36mextract_features_dev\u001b[0;34m(document)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw_features_dev\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contains(%s)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features_dev,dev_tweets)\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with negative tweets.\n",
      "Done with positive tweets.\n",
      "Done with neutral tweets.\n",
      "[Negative accuracy]: 41/5=0.12\n",
      "[Negative precision]: 0.12\n",
      "[Negative recall]: 0.14\n",
      "[Positive accuracy]: 116/76=0.65\n",
      "[Positive precision]: 0.65\n",
      "[Positive recall]: 0.36\n",
      "[Neutral accuracy]: 199/64=0.32\n",
      "[Neutral precision]: 0.32\n",
      "[Neutral recall]: 0.57\n",
      "[Total accuracy]: 145/356=0.40\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'set' and 'set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-fedf65597a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_neu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-fe01148cee0c>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(t_pos, t_neg, t_neu, classifier)\u001b[0m\n\u001b[1;32m     54\u001b[0m                                               (pos_cnt+neg_cnt+neu_cnt)/float(len(t_neg)+len(t_pos)+len(t_neu)))))\n\u001b[1;32m     55\u001b[0m     print('[Total precision]: %s'% \n\u001b[0;32m---> 56\u001b[0;31m           (nltk.precision(resu['neutral']+resu['positive']+resu['neutral'],\n\u001b[0m\u001b[1;32m     57\u001b[0m                           orig['positive']+orig['negative']+orig['neutral']))) \n\u001b[1;32m     58\u001b[0m     print('[Total recall]: %s'% \n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'set' and 'set'"
     ]
    }
   ],
   "source": [
    "evaluation(d_pos,d_neg,d_neu,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-0f29653fca98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtweets_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mscuser/anaconda2/lib/python2.7/site-packages/nltk/classify/naivebayes.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Increment freq(fval|label, fname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                 \u001b[0mfeature_freqdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfval\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m                 \u001b[0;31m# Record that fname can take the value fval.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mfeature_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mscuser/anaconda2/lib/python2.7/site-packages/nltk/probability.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, val)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features_tr,tweets_tr)\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation(t_pos,t_neg,t_neu,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(t_pos,t_neg,t_neu,classifier):\n",
    "    neg_cnt = 0\n",
    "    pos_cnt = 0\n",
    "    neu_cnt=0\n",
    "    resu={}\n",
    "    orig={}\n",
    "    resu['negative'] = set()\n",
    "    resu['positive'] = set()\n",
    "    resu['neutral']= set()\n",
    "    orig['negative'] = set()\n",
    "    orig ['positive']= set()\n",
    "    orig['neutral']=set()\n",
    "    ind=0\n",
    "    for obj in t_neg:\n",
    "        res =  classifier.classify(extract_features_tr(obj.split()))\n",
    "        resu[res].add(ind)\n",
    "        orig['negative'].add(ind)\n",
    "        if(res == 'negative'):\n",
    "            neg_cnt = neg_cnt + 1\n",
    "        ind+=1\n",
    "    print 'Done with negative tweets.'\n",
    "\n",
    "    for obj in t_pos:\n",
    "        res =  classifier.classify(extract_features_tr(obj.split()))\n",
    "        resu[res].add(ind)\n",
    "        orig['positive'].add(ind)\n",
    "        if(res == 'positive'):\n",
    "            pos_cnt = pos_cnt + 1\n",
    "        ind+=1\n",
    "    print 'Done with positive tweets.'\n",
    "\n",
    "    for obj in t_neu:\n",
    "        res =  classifier.classify(extract_features_tr(obj.split()))\n",
    "        resu[res].add(ind)\n",
    "        orig['neutral'].add(ind)\n",
    "        if(res == 'neutral'):\n",
    "            neu_cnt = neu_cnt + 1\n",
    "        ind+=1\n",
    "    print 'Done with neutral tweets.'\n",
    "\n",
    "    print('[Negative accuracy]: %s/%s=%.4s'  % (len(t_neg),neg_cnt,neg_cnt/float(len(t_neg))))\n",
    "    print('[Negative precision]: %.4s'  % (nltk.precision(resu['negative'],orig['negative'])))    \n",
    "    print('[Negative recall]: %.4s'  % (nltk.recall(resu['negative'],orig['negative'])))\n",
    "\n",
    "    print('[Positive accuracy]: %s/%s=%.4s'  % (len(t_pos),pos_cnt,pos_cnt/float(len(t_pos))))\n",
    "    print('[Positive precision]: %.4s'  %(nltk.precision(resu['positive'],orig['positive'])))    \n",
    "    print('[Positive recall]: %.4s'  % (nltk.recall(resu['positive'],orig['positive'])))\n",
    "\n",
    "    print('[Neutral accuracy]: %s/%s=%.4s'  % (len(t_neu),neu_cnt,neu_cnt/float(len(t_neu))))\n",
    "    print('[Neutral precision]: %.4s'  %(nltk.precision(resu['neutral'],orig['neutral'])))    \n",
    "    print('[Neutral recall]: %.4s'  % (nltk.recall(resu['neutral'],orig['neutral'])))\n",
    "\n",
    "    print('[Total accuracy]: %s/%s=%.4s'  % ((pos_cnt+neg_cnt+neu_cnt,len(t_neg)+len(t_pos)+len(t_neu),\n",
    "                                              (pos_cnt+neg_cnt+neu_cnt)/float(len(t_neg)+len(t_pos)+len(t_neu)))))\n",
    "    print('[Total precision]: %s'% \n",
    "          (nltk.precision(resu['neutral']+resu['positive']+resu['neutral'],\n",
    "                          orig['positive']+orig['negative']+orig['neutral']))) \n",
    "    print('[Total recall]: %s'% \n",
    "          (nltk.recall(resu['neutral']+resu['positive']+resu['neutral'],\n",
    "                          orig['positive']+orig['negative']+orig['neutral'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.446222791293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.1, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "text=[' '.join(x[0]) for x in dev_tweets]\n",
    "sent=[x[1] for x in dev_tweets]\n",
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "clf.fit(text,sent)\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2),(1,3),(1,4)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (0.1,0.01,0.001),\n",
    "}\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(text,sent)\n",
    "print gs_clf.best_score_ \n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print gs_clf.best_params_['clf__alpha']\n",
    "clf=[]\n",
    "if gs_clf.best_params_['tfidf__use_idf']==True:\n",
    "    clf = Pipeline([('vect', CountVectorizer(gs_clf.best_params_['vect__ngram_range'])),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(gs_clf.best_params_['clf__alpha'])),\n",
    "])\n",
    "else:\n",
    "    clf = Pipeline([('vect', CountVectorizer(gs_clf.best_params_['vect__ngram_range'])),\n",
    "                     ('clf', MultinomialNB(gs_clf.best_params_['clf__alpha'])),\n",
    "])\n",
    "text=[' '.join(x[0]) for x in tweets_tr]\n",
    "sent=[x[1] for x in tweets_tr]\n",
    "\n",
    "clf.fit(text,sent)\n",
    "test_text=[x[1][0] for x in d_te.iterrows()]\n",
    "target=[x[1][1] for x in d_te.iterrows()]\n",
    "result=clf.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.50      0.56      0.53      5439\n",
      "   negative       0.40      0.20      0.27      2271\n",
      "    neutral       0.58      0.62      0.60      7727\n",
      "\n",
      "avg / total       0.53      0.54      0.53     15437\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 450, 1225,  596],\n",
       "       [ 489, 4800, 2438],\n",
       "       [ 178, 2221, 3040]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(target, result,['positive','negative','neutral']))\n",
    "metrics.confusion_matrix(target,result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I decided to use the Naive Bayes algorithm as it is the one the is generally most appropriate for text sentiment analysis. The selected features are a single word,because the bigrams produced the same results but required much more time than the unigram case"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
