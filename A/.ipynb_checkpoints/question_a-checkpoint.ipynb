{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk import precision,recall\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files and put them in a pandas dataset.There are three different types: the train dataset(in order to train the classifier),the development set(in order to tune the hyperparameters of the desired algorithm),the test set(the set we will test the algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train tweets read  16045\n",
      "Total test tweets read  20342\n",
      "Total dev train tweets read  2000\n",
      "Total dev test tweets read  489\n"
     ]
    }
   ],
   "source": [
    "cols = ['id','sentiment','tweet']\n",
    "tr_files=['twitter-2013train-A.tsv','twitter-2015train-A.tsv','twitter-2016train-A.tsv']\n",
    "dev_files_te='twitter-2016dev-A.tsv'\n",
    "dev_files_tr='twitter-2016devtest-A.tsv'\n",
    "te_files='twitter-2016test-A.tsv'\n",
    "list_=[]\n",
    "for file_ in tr_files:\n",
    "    df = pd.read_csv(file_,names=cols, header=None,sep='\\t')\n",
    "    list_.append(df)\n",
    "df_train = pd.concat(list_)\n",
    "\n",
    "df = pd.read_csv(te_files,names=cols, header=None,sep='\\t')\n",
    "df_test=df\n",
    "    \n",
    "df = pd.read_csv(dev_files_tr,names=cols, header=None,sep='\\t')\n",
    "df_dev_tr = df\n",
    "\n",
    "df = pd.read_csv(dev_files_te,names=cols, header=None,sep='\\t')\n",
    "df_dev_te = df\n",
    "\n",
    "print 'Total train tweets read ',len(df_train)\n",
    "print 'Total test tweets read ',len(df_test)\n",
    "print 'Total dev train tweets read ',len(df_dev_tr)\n",
    "print 'Total dev test tweets read ',len(df_dev_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the datasets that their tweets are available.Remove the ones that their tweet text says 'Not available'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of train data:                    id sentiment  \\\n",
      "0  264183816548130816  positive   \n",
      "3  264249301910310912  negative   \n",
      "6  264105751826538497  positive   \n",
      "7  264094586689953794  negative   \n",
      "9  254941790757601280  negative   \n",
      "\n",
      "                                               tweet  \n",
      "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
      "3  Iranian general says Israel's Iron Dome can't ...  \n",
      "6  with J Davlar 11th. Main rivals are team Polan...  \n",
      "7  Talking about ACT's &amp;&amp; SAT's, deciding...  \n",
      "9  They may have a SuperBowl in Dallas, but Dalla...  \n",
      "Sample of test data:                    id sentiment  \\\n",
      "0  619950566786113536   neutral   \n",
      "1  619969366986235905   neutral   \n",
      "3  619974445185302528   neutral   \n",
      "4  619987808317407232  positive   \n",
      "5  619994586182619136  positive   \n",
      "\n",
      "                                               tweet  \n",
      "0  Picturehouse's, Pink Floyd's, 'Roger Waters: T...  \n",
      "1  Order Go Set a Watchman in store or through ou...  \n",
      "3  If you could ask an onstage interview question...  \n",
      "4  A portion of book sales from our Harper Lee/Go...  \n",
      "5  Excited to read \"Go Set a Watchman\" on Tuesday...  \n"
     ]
    }
   ],
   "source": [
    "df_train=df_train[df_train.tweet!='Not Available']\n",
    "df_test=df_test[df_test.tweet!='Not Available']\n",
    "df_dev_te=df_dev_te[df_dev_te.tweet!='Not Available']\n",
    "df_dev_tr =df_dev_tr[df_dev_tr.tweet!='Not Available']\n",
    "print 'Sample of train data:',df_train.head()\n",
    "print 'Sample of test data:',df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of sentimens (positive,negative,neutral) that exist in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiments in train: neutral     5143\n",
      "positive    5117\n",
      "negative    1658\n",
      "Name: sentiment, dtype: int64\n",
      "Sentiments in test: neutral     7727\n",
      "positive    5439\n",
      "negative    2271\n",
      "Name: sentiment, dtype: int64\n",
      "Sentiments in dev train test: positive    777\n",
      "neutral     539\n",
      "negative    246\n",
      "Name: sentiment, dtype: int64\n",
      "Sentiments in dev test: neutral     199\n",
      "positive    116\n",
      "negative     41\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print 'Sentiments in train:',df_train.sentiment.value_counts()\n",
    "print 'Sentiments in test:',df_test.sentiment.value_counts()\n",
    "print 'Sentiments in dev train test:',df_dev_tr.sentiment.value_counts()\n",
    "print 'Sentiments in dev test:',df_dev_te.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the neccessary columns and drop id column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_tr=df_train[['tweet','sentiment']]\n",
    "d_te=df_test[['tweet','sentiment']]\n",
    "dev_tr=df_dev_tr[['tweet','sentiment']]\n",
    "dev_te=df_dev_te[['tweet','sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove tweets that their text has any useless (for sentiment analysis purposes) mentions to other users,html links,hashtag symbol from hashtags and RT (retweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "def clean_text(dataset):\n",
    "    tweets=[]\n",
    "    for index, row in dataset.iterrows():\n",
    "        words_filtered = [e.lower() for e in row.tweet.split() if len(e) >= 3]\n",
    "        words_cleaned = [word.translate(None, string.punctuation) for word in words_filtered\n",
    "            if 'http' not in word\n",
    "            and not word.startswith('@')\n",
    "            and not word.startswith('#')\n",
    "            and word != 'RT'\n",
    "            and word not in stopwords_set]\n",
    "        words_without_stopwords = [word for word in words_cleaned if not word in stopwords_set]\n",
    "        tweets.append((words_cleaned,row.sentiment))\n",
    "    return tweets\n",
    "        \n",
    "train=clean_text(d_tr)\n",
    "dev_tr=clean_text(dev_tr)\n",
    "dev_te=clean_text(dev_te)\n",
    "test=clean_text(d_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier with the development set to find the best hyperparameters of the algorithm. Pipeline will execute the functions sequentially.We fit the dev train data to MultinomialNB classifier.The hyperparameters to tune the algorithm are :\n",
    "\n",
    "ngram_range: The vocabulary of the algorithm will contain (1,1)->unigrams,(1,2)-> unigram and bigrams,(1,3)->unigrams,bigrams and trigrams.It is an argument pass to CountVectorizer function that converts a collection of texts to a matrix of token counts.\n",
    "\n",
    "use_idf:If this is true,it uses the result of CountVectorizer into TfidfTransformer that transforms a count matrix to a normalized tf or tf-idf representation.Otherwise,this is skipped.\n",
    "\n",
    "alpha:Additive (Laplace/Lidstone) smoothing parameter.\n",
    "\n",
    "fit_prior: Whether to learn class prior probabilities or not. If false, a uniform prior will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB has best score of  0.446862996159  and best parameters  {'vect__ngram_range': (2, 3), 'clf__fit_prior': True, 'tfidf__use_idf': True, 'clf__alpha': 0.1}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.34      0.98      0.50       116\n",
      "   negative       0.00      0.00      0.00        41\n",
      "    neutral       0.69      0.06      0.10       199\n",
      "\n",
      "avg / total       0.49      0.35      0.22       356\n",
      "\n",
      "Accuracy  0.351123595506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mscuser/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "text=[' '.join(x[0]) for x in dev_tr]\n",
    "sent=[x[1] for x in dev_tr]\n",
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "clf.fit(text,sent)\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2),(1,3),(2,3),(2,4)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (0.1,0.01,0.001),\n",
    "              'clf__fit_prior':(True,False),\n",
    "}\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(text,sent)\n",
    "print 'MultinomialNB has best score of ',gs_clf.best_score_,' and best parameters ',gs_clf.best_params_\n",
    "test_text=[' '.join(x[0]) for x in dev_te]\n",
    "target=[x[1] for x in dev_te]\n",
    "result=clf.predict(test_text)\n",
    "\n",
    "print(metrics.classification_report(target, result,['positive','negative','neutral']))\n",
    "metrics.confusion_matrix(target,result)\n",
    "print 'Accuracy ',accuracy_score(result,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the optimal parameters in order to fit the training data to the MultinomialNB and then apply the test set and measure the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished the fitting.\n"
     ]
    }
   ],
   "source": [
    "clf=[]\n",
    "if gs_clf.best_params_['tfidf__use_idf']==True:\n",
    "    clf = Pipeline([('vect', CountVectorizer(gs_clf.best_params_['vect__ngram_range'])),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(gs_clf.best_params_['clf__alpha'])),\n",
    "])\n",
    "else:\n",
    "    clf = Pipeline([('vect', CountVectorizer(gs_clf.best_params_['vect__ngram_range'])),\n",
    "                     ('clf', MultinomialNB(gs_clf.best_params_['clf__alpha'])),\n",
    "])\n",
    "text=[' '.join(x[0]) for x in train]\n",
    "sent=[x[1] for x in train]\n",
    "\n",
    "clf.fit(text,sent)\n",
    "print 'Finished the fitting.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_text=[' '.join(x[0]) for x in test]\n",
    "target=[x[1] for x in test]\n",
    "result=clf.predict(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate various metric for the algorithm:\n",
    "\n",
    "precision: counts the true positives(how useful the results are).If the algorithm return 10 positive tweets and 5 of them are positive,the precision is 5/10=0.5.\n",
    "\n",
    "recall: counts the false positives(how complete the results are).If the algorithm return 10 positive tweets and 5 of them are indeed positive,while all of the positive tweets are 20 then the recall is 10/20.\n",
    "\n",
    "f1-score:The F1 score is the harmonic average of the precision and recall. Measures test accuracy of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.48      0.67      0.56      5439\n",
      "   negative       0.50      0.19      0.28      2271\n",
      "    neutral       0.60      0.54      0.57      7727\n",
      "\n",
      "avg / total       0.54      0.54      0.52     15437\n",
      "\n",
      "Accuracy  0.536891883138\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target, result,['positive','negative','neutral']))\n",
    "metrics.confusion_matrix(target,result)\n",
    "print 'Accuracy ',accuracy_score(result,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h4>I decided to use the MultinomialNB algorithm as it is the one the is generally most appropriate for text sentiment analysis as it produced slightly better results without requiring excessive amount of time to be run. The features are selected based on the GridSearch and in most occassions using bigram and trigram helped improved the overal performance of the algorithm.</h4>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
